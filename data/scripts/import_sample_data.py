#!/usr/bin/env python3
"""
å¯¼å…¥ç¤ºä¾‹æ•°æ®åˆ°æ•°æ®åº“
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import asyncio
import json
from src.services.ollama_service import OllamaService
from src.database.vector_store import PostgreSQLVectorStore

async def import_sample_data():
    """å¯¼å…¥ç¤ºä¾‹æ•°æ®"""
    print("="*50)
    print("å¯¼å…¥ç¤ºä¾‹æ•°æ®åˆ°æ•°æ®åº“")
    print("="*50)
    
    try:
        # åˆå§‹åŒ–æœåŠ¡
        ollama = OllamaService()
        vector_store = PostgreSQLVectorStore()
        await vector_store.connect()
        
        # 1. å¯¼å…¥æ–‡æœ¬æ•°æ®
        print("\nğŸ“„ å¯¼å…¥æ–‡æœ¬æ•°æ®...")
        text_file = Path("data/raw/text/1.md")
        if text_file.exists():
            content = text_file.read_text(encoding="utf-8")
            print(f"  è¯»å–æ–‡ä»¶: {text_file.name} ({len(content)} å­—ç¬¦)")
            
            # ç”ŸæˆåµŒå…¥
            print("  ç”Ÿæˆæ–‡æœ¬åµŒå…¥...")
            embedding_result = ollama.generate_embedding(content)
            print(f"    åµŒå…¥ç»´åº¦: {len(embedding_result.embedding)}")
            print(f"    è€—æ—¶: {embedding_result.duration_ms:.2f}ms")
            
            # æ’å…¥æ•°æ®åº“
            doc_id = await vector_store.insert_document(
                content=content,
                embedding=embedding_result.embedding,
                metadata={
                    "source_file": text_file.name,
                    "file_size": len(content),
                    "import_time": "2026-01-07"
                },
                source="æ ¡å›­å¯¼è§ˆæ–‡æ¡£"
            )
            print(f"  âœ… æ–‡æ¡£å¯¼å…¥æˆåŠŸ: {doc_id}")
        else:
            print(f"  âŒ æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {text_file}")
            return False
        
        # 2. å¯¼å…¥å›¾åƒæ•°æ®
        print("\nğŸ–¼ï¸  å¯¼å…¥å›¾åƒæ•°æ®...")
        image_dir = Path("data/raw/images")
        image_files = list(image_dir.glob("*.png"))
        
        image_ids = []
        for image_file in image_files:
            print(f"  å¤„ç†å›¾åƒ: {image_file.name}")
            
            # ç”Ÿæˆå›¾åƒæè¿°
            print("    ç”Ÿæˆå›¾åƒæè¿°...")
            try:
                description_result = ollama.generate_image_description(str(image_file))
                print(f"    æè¿°é•¿åº¦: {len(description_result.text)} å­—ç¬¦")
                print(f"    è€—æ—¶: {description_result.duration_ms:.2f}ms")
                
                # ç”Ÿæˆæè¿°çš„åµŒå…¥
                print("    ç”Ÿæˆæè¿°åµŒå…¥...")
                desc_embedding_result = ollama.generate_embedding(description_result.text)
                
                # æ’å…¥æ•°æ®åº“
                image_id = await vector_store.insert_image_description(
                    image_path=str(image_file),
                    vlm_description=description_result.text,
                    embedding=desc_embedding_result.embedding,
                    metadata={
                        "source_file": image_file.name,
                        "file_size": image_file.stat().st_size,
                        "import_time": "2026-01-07"
                    },
                    image_size=f"{image_file.stat().st_size} bytes",
                    file_format="png"
                )
                image_ids.append(image_id)
                print(f"    âœ… å›¾åƒå¯¼å…¥æˆåŠŸ: {image_id}")
                
            except Exception as e:
                print(f"    âŒ å›¾åƒå¤„ç†å¤±è´¥: {e}")
                continue
        
        if not image_ids:
            print("  âš ï¸  æ²¡æœ‰æˆåŠŸå¯¼å…¥çš„å›¾åƒ")
            return False
        
        # 3. åˆ›å»ºæ–‡æœ¬-å›¾åƒå…³è”
        print("\nğŸ”— åˆ›å»ºæ–‡æœ¬-å›¾åƒå…³è”...")
        if image_ids:
            for image_id in image_ids:
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šå‡è®¾æ‰€æœ‰å›¾åƒéƒ½ä¸æ–‡æ¡£ç›¸å…³
                relation_id = await vector_store.create_text_image_relation(
                    document_id=doc_id,
                    image_id=image_id,
                    similarity_score=0.8,  # å‡è®¾ç›¸ä¼¼åº¦
                    relation_type="æ ¡å›­å»ºç­‘"
                )
                print(f"  âœ… åˆ›å»ºå…³è”: {relation_id}")
        
        # 4. éªŒè¯æ•°æ®
        print("\nğŸ“Š éªŒè¯å¯¼å…¥çš„æ•°æ®...")
        doc_count = await vector_store.get_document_count()
        image_count = await vector_store.get_image_count()
        
        print(f"  æ–‡æ¡£æ•°é‡: {doc_count}")
        print(f"  å›¾åƒæè¿°æ•°é‡: {image_count}")
        
        await vector_store.close()
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_imported_data():
    """æµ‹è¯•å¯¼å…¥çš„æ•°æ®"""
    print("\n" + "="*50)
    print("æµ‹è¯•å¯¼å…¥çš„æ•°æ®")
    print("="*50)
    
    try:
        vector_store = PostgreSQLVectorStore()
        await vector_store.connect()
        
        # è·å–æ‰€æœ‰æ–‡æ¡£
        print("ğŸ“„ æ£€ç´¢æ–‡æ¡£...")
        test_embedding = [0.1] * 1024  # æµ‹è¯•ç”¨åµŒå…¥
        results = await vector_store.search_similar_documents(test_embedding, top_k=3)
        
        print(f"  æ‰¾åˆ° {len(results)} ä¸ªæ–‡æ¡£")
        for i, result in enumerate(results):
            print(f"  æ–‡æ¡£ {i+1}:")
            print(f"    ID: {result.id}")
            print(f"    ç›¸å…³æ€§: {result.score:.3f}")
            preview = result.content[:100] + "..." if len(result.content) > 100 else result.content
            print(f"    å†…å®¹é¢„è§ˆ: {preview}")
        
        # è·å–æ‰€æœ‰å›¾åƒ
        print("\nğŸ–¼ï¸  æ£€ç´¢å›¾åƒ...")
        image_results = await vector_store.search_similar_images(test_embedding, top_k=3)
        
        print(f"  æ‰¾åˆ° {len(image_results)} ä¸ªå›¾åƒ")
        for i, result in enumerate(image_results):
            print(f"  å›¾åƒ {i+1}:")
            print(f"    ID: {result.id}")
            print(f"    è·¯å¾„: {result.image_path}")
            print(f"    ç›¸å…³æ€§: {result.score:.3f}")
            preview = result.vlm_description[:100] + "..." if len(result.vlm_description) > 100 else result.vlm_description
            print(f"    æè¿°é¢„è§ˆ: {preview}")
        
        await vector_store.close()
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»å‡½æ•°"""
    print("ç¤ºä¾‹æ•°æ®å¯¼å…¥å·¥å…·")
    print("="*60)
    
    # å¯¼å…¥æ•°æ®
    if not await import_sample_data():
        return 1
    
    # æµ‹è¯•æ•°æ®
    if not await test_imported_data():
        return 1
    
    print("\n" + "="*60)
    print("ğŸ‰ ç¤ºä¾‹æ•°æ®å¯¼å…¥å®Œæˆï¼")
    print("="*60)
    print("\næ•°æ®å·²æˆåŠŸå¯¼å…¥æ•°æ®åº“ã€‚")
    print("ç°åœ¨å¯ä»¥è¿è¡ŒRAGç³»ç»Ÿæµ‹è¯•äº†ã€‚")
    
    return 0

if __name__ == "__main__":
    sys.exit(asyncio.run(main()))